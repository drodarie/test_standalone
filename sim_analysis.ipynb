{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "from os.path import *\n",
    "from os import listdir, makedirs\n",
    "import h5py\n",
    "import json\n",
    "import copy\n",
    "import sys\n",
    "sys.path.append('../Databases/')\n",
    "from database import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_FOLDER = realpath('.')\n",
    "Dver = 'v10'\n",
    "Simulation = 'Pois_SSCTx2'\n",
    "SIM_FOLDER = 'save/'+Dver+'/'+Simulation+'/'\n",
    "NEURON_PREFIX = 'neuron'\n",
    "NEST_PREFIX = 'nest'\n",
    "\n",
    "databases_file = join(ROOT_FOLDER, \"ElecDB2.db\")\n",
    "file_ = join(ROOT_FOLDER, 'whole_brain_model_Nest.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def hex_to_rgb(value):\n",
    "    value = value.lstrip('#')\n",
    "    lv = len(value)\n",
    "    return np.float32([float(int(value[i:i + lv // 3], 16)) for i in range(0, lv, lv // 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeLegendFig(figname, labels, colors, numColumns = 1):\n",
    "    f = lambda m,c: plt.plot([],[],marker=m, color=c, ls=\"none\")[0]\n",
    "    handles = [f(\"s\", colors[i]) for i in range(3)]\n",
    "    labelsMAXLEN = np.array([len(str1) for str1 in labels])\n",
    "    labelsSPLIT = np.split(labels, np.array(range(0,1+len(labels),int(np.ceil(float(len(labels))/float(numColumns)))))[1:] )\n",
    "    colorsSPLIT = np.split(colors, np.array(range(0,1+len(labels),int(np.ceil(float(len(labels))/float(numColumns)))))[1:] )\n",
    "    colLength = (0.5+0.13*np.max(labelsMAXLEN))\n",
    "    fig = plt.figure(figsize=( colLength*float(numColumns), 0.25*float(len(colors))/float(numColumns)))\n",
    "    for iC in range(numColumns):\n",
    "        patches = [mpatches.Patch(color=color, label=label) for label, color in zip(labelsSPLIT[iC], colorsSPLIT[iC])]\n",
    "        fig.legend(patches, labelsSPLIT[iC], loc=(0.0+float(iC)*(1.0/float(numColumns)),0.0), frameon=False)\n",
    "    plt.savefig(figname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "included_regions = [\"Primary somatosensory area, lower limb\", 'Ventral posteromedial nucleus of the thalamus'] # Specific regions of the database targeted\n",
    "regions_labels = ['SSCtx:HL', 'VPN'] \n",
    "\n",
    "db = BrainDB(databases_file)\n",
    "region_cond = db.getMouseBrainConds(leafs=True)\n",
    "# full_name contains the region name so we set the with_like flag\n",
    "region_cond.append(Region.table.condition(column=\"full_name\", \n",
    "                                          included=included_regions, with_like=True))\n",
    "request = db.getRegions(region_cond)\n",
    "id_to_region_dictionary = {}\n",
    "id_to_region_dictionary_ALLNAME = {}\n",
    "region_dictionary_to_id = {}\n",
    "region_dictionary_to_id_ALLNAME = {}\n",
    "region_dictionary_to_id_ALLNAME_parent = {}\n",
    "region_dictionary_to_id_parent = {}\n",
    "allname2name = {}\n",
    "name2allname = {}\n",
    "allnameOrder = {}\n",
    "regKeys = []\n",
    "region_names = []\n",
    "regions_ALLNAME_list = []\n",
    "is_leaf = []\n",
    "layers = {}\n",
    "\n",
    "id_to_color     = {}\n",
    "region_to_color = {}\n",
    "\n",
    "iterTMP = 0\n",
    "rows, headers = db.execute(request=request)\n",
    "for line in rows:\n",
    "    id_to_region_dictionary[line[0]] = line[1]\n",
    "    id_to_region_dictionary_ALLNAME[line[0]] = line[2]\n",
    "    region_dictionary_to_id[line[1]] = line[0]\n",
    "    region_dictionary_to_id_ALLNAME[line[2]] = line[0]\n",
    "\n",
    "    region_dictionary_to_id_ALLNAME_parent[line[2]] = line[2].rsplit(\"|\", 1)[1] \n",
    "    region_dictionary_to_id_parent[line[1]] = line[2].rsplit(\"|\", 2)[1]\n",
    "    allname2name [line[2]]= line[1]\n",
    "    name2allname [line[1]] = line[2]\n",
    "    allnameOrder [line[2]] = iterTMP; iterTMP+=1\n",
    "    regKeys.append(line[0])\n",
    "    region_names.append(line[1])\n",
    "    regions_ALLNAME_list.append(line[2])\n",
    "    is_leaf.append(line[5])\n",
    "    id_to_color[line[0]] = line[3]\n",
    "    region_to_color[line[1]] = line[3]\n",
    "\n",
    "    if line[2].find(\"Isocortex\")>=0:\n",
    "        if line[2].find(\"ayer 1\")>=0:   layers[line[0]]=1\n",
    "        elif line[2].find(\"ayer 2\")>=0: layers[line[0]]=2\n",
    "        elif line[2].find(\"ayer 3\")>=0: layers[line[0]]=3\n",
    "        elif line[2].find(\"ayer 4\")>=0: layers[line[0]]=4\n",
    "        elif line[2].find(\"ayer 5\")>=0: layers[line[0]]=5\n",
    "        elif line[2].find(\"ayer 6\")>=0: layers[line[0]]=6\n",
    "        else:                           layers[line[0]]=0\n",
    "    else:\n",
    "        layers[line[0]]=0\n",
    "\n",
    "is_leaf = np.array(is_leaf)\n",
    "filter_ = np.where(is_leaf==1)\n",
    "region_names = np.array(region_names)[filter_]\n",
    "regions_ALLNAME_list = np.array(regions_ALLNAME_list)[filter_]\n",
    "regions_ids = np.array(regKeys)[filter_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading h5 file\")\n",
    "h5file = h5py.File(file_, \"r\")\n",
    "type_names = [\"exc\", \"inh\", \"mod\"]\n",
    "cellTypes = np.array(h5file['neurons']['cellTypes'])\n",
    "type_ID_to_name = np.array(h5file['neurons']['cellTypesToName'])\n",
    "filter_ = np.zeros(cellTypes.size, dtype=bool)\n",
    "for type_name in type_names:\n",
    "    filter_ = np.logical_or(filter_, cellTypes==np.where(type_ID_to_name==type_name.encode('ascii'))[0])\n",
    "Larea   = h5file['neurons'][\"regions\"][filter_]\n",
    "isExc = h5file['neurons'][\"excitatory\"][:]\n",
    "etype   = h5file['neurons'][\"eTypes\"][:]\n",
    "ETTN    = h5file['neurons'][\"eTypesToName\"][:]\n",
    "mtype   = h5file['neurons'][\"neuronTypes\"][:]\n",
    "CTTN    = h5file['neurons'][\"neuronTypesToName\"][:]\n",
    "xs      = h5file['neurons'][\"x\"][:]\n",
    "ys      = h5file['neurons'][\"y\"][:]\n",
    "zs      = h5file['neurons'][\"z\"][:]\n",
    "Umtype = np.unique(mtype)\n",
    "Uetype = np.unique(etype)\n",
    "\n",
    "LTN = [\"ALL\", \"Layer 1\", \"Layer 2\", \"Layer 3\", \"Layer 4\", \"Layer 5\", \"Layer 6\"]\n",
    "LTNei = [\"ALL\", \"Layer 1 inh\", \"Layer 1 exc\", \"Layer 2 inh\", \"Layer 2 exc\", \"Layer 3 inh\", \"Layer 3 exc\", \"Layer 4 inh\", \"Layer 4 exc\", \"Layer 5 inh\", \"Layer 5 exc\", \"Layer 6 inh\", \"Layer 6 exc\"]\n",
    "print(\"h5 file loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_cont = json.loads(open(join(SIM_FOLDER, \"conversion.json\"), \"r\").read())\n",
    "json_convert = {}\n",
    "for k, v in json_cont.items():\n",
    "    json_convert[str(v)] = int(k)\n",
    "del json_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIM_OUTPUTS = {join(SIM_FOLDER, NEURON_PREFIX+'_output'):False, \n",
    "               join(SIM_FOLDER, NEST_PREFIX+'_output'):True\n",
    "              }\n",
    "\n",
    "time_from = 20.00\n",
    "time_to = 2080.00\n",
    "only_spike = False\n",
    "\n",
    "for sim, convert in SIM_OUTPUTS.items():\n",
    "    spikes = {\"senders\":[], \"times\":[], \"regions\":[], \"layer\":[], \"mtype\":[], \"etype\":[]}\n",
    "    multimeters = {\"senders\":[], \"times\":[], \"regions\":[], \"layer\":[], \"mtype\":[], \"etype\":[], \"potentials\":[]}\n",
    "    for f in listdir(sim):\n",
    "        file_ = join(sim, f)\n",
    "        if isfile(file_) and (\"multimeter\" not in file_ or not only_spike):\n",
    "            print(f)\n",
    "            with open(file_, 'r') as f:\n",
    "                for line in f:\n",
    "                    splitLine = line.split()\n",
    "                    if convert:\n",
    "                        gid = json_convert[splitLine[0]]\n",
    "                    else:\n",
    "                        gid = int(splitLine[0])\n",
    "                    larea = Larea[gid]\n",
    "                    if float(splitLine[1]) >= time_from and float(splitLine[1]) <= float(time_to) and larea in regions_ids:\n",
    "                        if \"spike_detector-\" in file_:\n",
    "                            spikes[\"senders\"].append(gid)\n",
    "                            spikes[\"times\"].append(float(splitLine[1]))\n",
    "                            spikes[\"regions\"].append(larea)\n",
    "                            spikes[\"layer\"].append(layers[larea])\n",
    "                            spikes[\"mtype\"].append(mtype[gid])\n",
    "                            spikes[\"etype\"].append(etype[gid]) \n",
    "                        elif \"multimeter\" in file_:\n",
    "                            multimeters[\"senders\"].append(gid)\n",
    "                            multimeters[\"times\"].append(float(splitLine[1]))\n",
    "                            multimeters[\"potentials\"].append(float(splitLine[2]))\n",
    "                            multimeters[\"regions\"].append(larea)\n",
    "                            multimeters[\"layer\"].append(layers[larea])\n",
    "                            multimeters[\"mtype\"].append(mtype[gid])\n",
    "                            multimeters[\"etype\"].append(etype[gid])\n",
    "                    elif float(splitLine[1]) > float(time_to):\n",
    "                        break;\n",
    "    spikes['senders'] = np.array(spikes['senders'])\n",
    "    spikes['times'] = np.array(spikes['times'])\n",
    "    spikes['regions'] = np.array(spikes['regions'])\n",
    "    spikes['layer'] = np.array(spikes['layer'])\n",
    "    spikes['mtype'] = np.array(spikes['mtype'])\n",
    "    spikes['etype'] = np.array(spikes['etype'])\n",
    "    \n",
    "    multimeters['senders'] = np.array(multimeters['senders'])\n",
    "    multimeters['times'] = np.array(multimeters['times'])\n",
    "    multimeters['potentials'] = np.array(multimeters['potentials'])\n",
    "    multimeters['regions'] = np.array(multimeters['regions'])\n",
    "    multimeters['layer'] = np.array(multimeters['layer'])\n",
    "    multimeters['mtype'] = np.array(multimeters['mtype'])\n",
    "    multimeters['etype'] = np.array(multimeters['etype'])\n",
    "    if len(spikes['senders']) <=0:\n",
    "        print(\"No spikes for the interval selected.\")\n",
    "    SIM_OUTPUTS[sim]= [copy.deepcopy(spikes), copy.deepcopy(multimeters)]\n",
    "    del spikes, multimeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_ctx = []\n",
    "ids_thal = []\n",
    "for id_reg in regions_ids:\n",
    "    if included_regions[0] in id_to_region_dictionary_ALLNAME[id_reg]:\n",
    "        ids_ctx.append(id_reg)\n",
    "    elif included_regions[1] in id_to_region_dictionary_ALLNAME[id_reg]:\n",
    "        ids_thal.append(id_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spikes plots\n",
    "nest_res = SIM_OUTPUTS[join(SIM_FOLDER, NEST_PREFIX+'_output')][0]\n",
    "nrn_res = SIM_OUTPUTS[join(SIM_FOLDER, NEURON_PREFIX+'_output')][0]\n",
    "\n",
    "dt = 0.1\n",
    "w_single = 500 # steps ie 20ms\n",
    "time_resolution = dt /1000. # in second\n",
    "\n",
    "ids_roi = ids_ctx\n",
    "roi_name = \"SSCtx-HL\"\n",
    "# roi_name = \"Thal-VPM\"\n",
    "# roi_name = \"ALL\"\n",
    "sim_res = nrn_res\n",
    "# sim_name = \"NEST\"\n",
    "sim_name = \"Neuron\"\n",
    "splitter = \"layer\"\n",
    "with_exc = True\n",
    "names = LTNei\n",
    "\n",
    "if not exists(join(SIM_FOLDER, sim_name, splitter)):\n",
    "    makedirs(join(SIM_FOLDER, sim_name, splitter))\n",
    "filter_ = np.in1d(sim_res['regions'], ids_roi)\n",
    "loc_gids = sim_res[\"senders\"][filter_]\n",
    "loc_filters = sim_res[splitter][filter_]\n",
    "if with_exc:\n",
    "    loc_filters=loc_filters*2+isExc[loc_gids]-1\n",
    "id_times = np.int64(np.round((sim_res['times'][filter_]-time_from)/dt))\n",
    "\n",
    "#id_times[loc_filters!=1] = 0\n",
    "\n",
    "uniq_filter = np.unique(loc_filters)\n",
    "num_filter = len(uniq_filter)\n",
    "convert = np.zeros(np.max(uniq_filter)+1, int)\n",
    "inv_convert = np.zeros(num_filter, int)\n",
    "for i in range(num_filter):\n",
    "    convert[uniq_filter[i]] = i\n",
    "    inv_convert[i] = uniq_filter[i]\n",
    "\n",
    "filter_colors = np.zeros((num_filter+1, 3), np.float32)\n",
    "for i in range(num_filter):\n",
    "    if i<10:\n",
    "        filter_colors[i+1] = hex_to_rgb(plt.rcParams['axes.prop_cycle'].by_key()['color'][i])/255.\n",
    "    else:\n",
    "        np.random.seed(i+i*10)\n",
    "        filter_colors[i+1] = np.random.rand(3)\n",
    "        if np.sum(filter_colors[i+1])<1.5: filter_colors[i+1] *= 1.5/np.sum(filter_colors[i+1])\n",
    "        filter_colors[i+1][filter_colors[i+1]>1.0] = 1.0\n",
    "\n",
    "_, indexes = np.unique(loc_gids, return_index=True)\n",
    "translate_local2global = loc_gids[indexes]\n",
    "translate_global2local = -np.ones(np.max(translate_local2global)+1, np.int64)\n",
    "translate_global2local[translate_local2global] = range(len(translate_local2global))\n",
    "\n",
    "spikes2D = np.zeros((int(round((time_to-time_from)/dt))+1,len(translate_local2global)), np.int8)\n",
    "spikes2D[id_times,translate_global2local[loc_gids]] = 1\n",
    "\n",
    "spikes2D_filter = spikes2D[:,np.argsort(loc_filters[indexes])]\n",
    "unsorted_colors = filter_colors[convert[loc_filters[indexes]]+1]\n",
    "gid2color = unsorted_colors[np.argsort(loc_filters[indexes])]\n",
    "\n",
    "\n",
    "nb_neurons = np.zeros(num_filter)\n",
    "ufilt = loc_filters[indexes]\n",
    "for i, uf in enumerate(uniq_filter):\n",
    "    nb_neurons[i] = len(np.where(ufilt==uf)[0])\n",
    "counts = np.zeros(num_filter+1)\n",
    "counts[1:] = np.cumsum(nb_neurons)\n",
    "\n",
    "length_fr = int(math.ceil(num_filter/2.0))*2\n",
    "fig = plt.figure(figsize=(15, 8+length_fr)) \n",
    "# Fig 1.1: Spike raster plot\n",
    "ax1 = plt.subplot2grid((6+length_fr,2), (0,0), colspan=2, rowspan=3)\n",
    "times, newIds = np.where(spikes2D_filter)\n",
    "ax1.scatter(times*dt, newIds, marker='.', c=gid2color[newIds], s=0.5)\n",
    "ax1.invert_yaxis()\n",
    "ax1.set_xlabel('Time in ms')\n",
    "ax1.set_ylabel('Neuron id')\n",
    "ax1.set_title('Spike raster plot')\n",
    "# ax1.set_xlim([100, 2000])\n",
    "\n",
    "kernel_single = signal.triang(w_single)*2/w_single # normalized boxcar kernel for single-trial firing rate\n",
    "R = signal.lfilter(kernel_single, 1, spikes2D_filter, axis=0)/time_resolution\n",
    "\n",
    "time_interval = np.arange(time_from+w_single*dt, time_to-w_single*dt+dt/10., dt)\n",
    "ax3 = plt.subplot2grid((6+length_fr,2), (3+length_fr,0), colspan=2, rowspan=3)\n",
    "for i in range(num_filter):\n",
    "    ax = plt.subplot2grid((6+length_fr,2), (3+i//2*2,i%2), rowspan=2)\n",
    "    mean = np.mean(R[:, int(counts[i]):int(counts[i+1])], axis=1)\n",
    "    fano_factor = np.var(R[:, int(counts[i]):int(counts[i+1])], axis=1)/mean\n",
    "    std = np.std(R[:, int(counts[i]):int(counts[i+1])], axis=1)\n",
    "    ax.fill_between(time_interval, (mean-std)[w_single:-w_single], (mean+std)[w_single:-w_single], alpha=0.5, color=filter_colors[i+1])\n",
    "    ax.plot(time_interval, mean[w_single:-w_single], color=filter_colors[i+1])\n",
    "    ax3.plot(time_interval, fano_factor[w_single:-w_single], color=filter_colors[i+1])\n",
    "    ax.set_xlabel('Time in ms')\n",
    "    ax.set_ylabel('Rate in Hz')\n",
    "    ax.set_title('Mean estimated firing rate for '+str(names[inv_convert[i]])+' (kernel width = '+ str(w_single*dt)+' ms)')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "ax3.set_xlabel('Time in ms')\n",
    "ax3.set_ylabel('Fano Factor')\n",
    "ax3.set_title('Estimate of the Fano Factor (kernel width = '+ str(w_single*dt)+' ms)')\n",
    "plt.savefig(join(SIM_FOLDER, sim_name, splitter, sim_name+\"_\"+roi_name+\"_\"+splitter+\"_fr.png\"))\n",
    "\n",
    "str_list = [\"\"]*num_filter\n",
    "for i in range(num_filter):\n",
    "    str_list[i] = names[uniq_filter[i]]\n",
    "makeLegendFig( SIM_FOLDER+\"/legend_\"+splitter+\".png\", labels=str_list, colors=filter_colors[1:], numColumns=num_filter//8+1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CV2 + FF against CV2\n",
    "fig = plt.figure(figsize =(10,6+length_fr))\n",
    "fano_factors = []\n",
    "cv2s = []\n",
    "isis_dist = []\n",
    "for i in range(num_filter):\n",
    "    filter_ = np.where(spikes2D_filter[:, int(counts[i]):int(counts[i+1])])\n",
    "    ms = []\n",
    "    spike_counts = np.sum(spikes2D_filter[:, int(counts[i]):int(counts[i+1])], axis=0)\n",
    "    mean_count = np.mean(spike_counts)\n",
    "    variance_count = np.var(spike_counts)\n",
    "    fano_factors.append(variance_count/mean_count)\n",
    "    isi = []\n",
    "    for k in range(spikes2D_filter[:, int(counts[i]):int(counts[i+1])].shape[1]):\n",
    "        isis = np.diff(filter_[0][filter_[1]==k])*0.1\n",
    "        if len(isis)>0:\n",
    "            isi.append(np.mean(isis))\n",
    "            ms = np.concatenate((ms,2*np.absolute(np.diff(isis))/(isis[0:isis.size-1] + isis[1:isis.size])))\n",
    "    cv2s.append(np.mean(ms))\n",
    "    isis_dist.append(isi)\n",
    "\n",
    "ax1 = plt.subplot2grid((6+length_fr,2), (0,0), colspan=2, rowspan=3)\n",
    "ax1.scatter(fano_factors, np.power(cv2s,2), c=filter_colors[1:])\n",
    "ax1.set_ylabel('CV2^2')\n",
    "ax1.set_ylim([1e-4,1e-1])\n",
    "ax1.set_xlabel('Fano Factor')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_title('Distribution of CV2^2 against Fano factors')\n",
    "\n",
    "for i in range(num_filter):\n",
    "    ax2 = plt.subplot2grid((6+length_fr,2), (3+i//2*2,i%2), rowspan=2)\n",
    "    ax2.hist(isis_dist[i],50, color=filter_colors[i+1])\n",
    "    ax2.set_xlabel('ISIs bins in ms')\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.set_title('Distribution of '+str(names[inv_convert[i]]) + ' ISIs')\n",
    "plt.tight_layout()\n",
    "plt.savefig(join(SIM_FOLDER, sim_name, splitter, sim_name+\"_\"+roi_name+\"_\"+splitter+\"_isi.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading masks\")\n",
    "mask_axial    = np.zeros((528,528), np.int16)\n",
    "mask_coronal  = np.zeros((528,528), np.int16)\n",
    "mask_sagittal = np.zeros((528,528), np.int16)\n",
    "mask_axial[   264-264:264+264,264-228:264+228] = np.int16(np.load(\"mask_axial.npy\"))\n",
    "mask_coronal[ 264-160:264+160,264-228:264+228] = np.int16(np.load(\"mask_coronal.npy\"))\n",
    "mask_sagittal[264-160:264+160,264-264:264+264] = np.int16(np.load(\"mask_sagittal.npy\")).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interval = 1 # ms\n",
    "tau_spike = 2.0 # ms\n",
    "\n",
    "extent_ = [-528*25.0*0.5,528*25.0*0.5,-528*25.0*0.5,528*25.0*0.5]\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots( 2,2, figsize=(16,16) )\n",
    "ax1.imshow( 255-20*mask_coronal, extent=extent_, cmap=\"gray\", vmin=0, vmax=255 )\n",
    "ax2.imshow( 255-20*mask_sagittal, extent=extent_, cmap=\"gray\", vmin=0, vmax=255  )\n",
    "ax3.imshow( 255-20*mask_axial, extent=extent_, cmap=\"gray\", vmin=0, vmax=255 )\n",
    "ax1.axis(extent_); ax1.axis('off')\n",
    "ax2.axis(extent_); ax2.axis('off')\n",
    "ax3.axis(extent_); ax3.axis('off')\n",
    "ax4.axis('off')\n",
    "sc1 = ax1.scatter( [],[], marker=\".\", s=20, edgecolor=\"none\")\n",
    "sc2 = ax2.scatter( [],[], marker=\".\", s=20, edgecolor=\"none\")\n",
    "sc3 = ax3.scatter( [],[], marker=\".\", s=20, edgecolor=\"none\")\n",
    "\n",
    "def animate(it_):\n",
    "    global id_times, dt, tau_spike, loc_gids, unsorted_colors, translate_global2local, xs, ys, zs\n",
    "    spikes_in_dT = np.where( (id_times<float(it_)/dt)*(id_times>float(it_)/dt-2.0*tau_spike/dt) )[0]\n",
    "    if spikes_in_dT.shape[0]>0:\n",
    "        sendersTMP = loc_gids[spikes_in_dT]\n",
    "        alphasTMP  = np.exp( (id_times[spikes_in_dT] - float(it_)/dt) / tau_spike*dt )\n",
    "        clrsTMP    = np.zeros((spikes_in_dT.shape[0],4))\n",
    "        clrsTMP[:,:3] = unsorted_colors[translate_global2local[sendersTMP], :]\n",
    "        clrsTMP[:, 3] = alphasTMP\n",
    "        sc1.set_offsets(np.array([-zs[ sendersTMP ], ys[ sendersTMP ]]).T)\n",
    "        sc1.set_color(clrsTMP)\n",
    "        sc2.set_offsets(np.array([xs[ sendersTMP ], ys[ sendersTMP ]]).T)\n",
    "        sc2.set_color(clrsTMP)\n",
    "        sc3.set_offsets(np.array([-zs[ sendersTMP ], -xs[ sendersTMP ]]).T)\n",
    "        sc3.set_color(clrsTMP)\n",
    "#         print(\"Spikes in \"+ str(it_), len(sendersTMP)) \n",
    "#     plt.title(\"Axial view of the brain activity - frame \"+str(it_)+ \" ms\")\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, range(int(1500), int(1600), interval), repeat=False)\n",
    "ani.save(join(SIM_FOLDER, sim_name, splitter, sim_name+\"_\"+roi_name+\"_\"+splitter+\"_spatial.mp4\"),fps=60, codec=\"h264\", extra_args=['-vcodec', 'libx264'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ = join(SIM_FOLDER, \"stimulation.gdf\")\n",
    "stim_spikes = []\n",
    "with open(file_, 'r') as f:\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        stim_spikes.append([float(splitLine[0]), int(splitLine[1])])\n",
    "stim_spikes = np.array(stim_spikes).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize =(15,6))\n",
    "plt.scatter(stim_spikes[0], stim_spikes[1], s=0.5)\n",
    "plt.title(\"Spikes Stimulus\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(SIM_FOLDER+ \"/\"+\"poisson_stimuli.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Membrane potential plots\n",
    "nest_res = SIM_OUTPUTS[join(SIM_FOLDER, NEST_PREFIX+'_output')][1]\n",
    "nrn_res = SIM_OUTPUTS[join(SIM_FOLDER, NEURON_PREFIX+'_output')][1]\n",
    "\n",
    "dt = 0.1\n",
    "time_resolution = dt /1000. # in second\n",
    "\n",
    "ids_roi = ids_ctx\n",
    "roi_name = \"SSCtx-HL\"\n",
    "# roi_name = \"Thal-VPM\"\n",
    "# roi_name = \"ALL\"\n",
    "sim_res = nrn_res\n",
    "# sim_name = \"NEST\"\n",
    "sim_name = \"Neuron\"\n",
    "splitter = \"layer\"\n",
    "with_exc = True\n",
    "names = LTNei\n",
    "\n",
    "if not exists(join(SIM_FOLDER, sim_name, splitter)):\n",
    "    makedirs(join(SIM_FOLDER, sim_name, splitter))\n",
    "filter_ = np.in1d(sim_res['regions'], ids_roi)\n",
    "loc_filters = sim_res[splitter][filter_]\n",
    "loc_gids = sim_res[\"senders\"][filter_]\n",
    "if with_exc:\n",
    "    loc_filters=loc_filters*2+isExc[loc_gids]-1\n",
    "id_times = np.int64(np.round(sim_res['times'][filter_]/dt))\n",
    "loc_potentials = sim_res['potentials'][filter_]\n",
    "\n",
    "uniq_filter = np.unique(loc_filters)\n",
    "num_filter = len(uniq_filter)\n",
    "convert = np.zeros(np.max(uniq_filter)+1, int)\n",
    "inv_convert = np.zeros(num_filter, int)\n",
    "for i in range(num_filter):\n",
    "    convert[uniq_filter[i]] = i\n",
    "    inv_convert[i] = uniq_filter[i]\n",
    "\n",
    "filter_colors = np.zeros((num_filter+1, 3), np.float32)\n",
    "for i in range(num_filter):\n",
    "    if i<10:\n",
    "        filter_colors[i+1] = hex_to_rgb(plt.rcParams['axes.prop_cycle'].by_key()['color'][i])/255.\n",
    "    else:\n",
    "        np.random.seed(i+i*10)\n",
    "        filter_colors[i+1] = np.random.rand(3)\n",
    "        if np.sum(filter_colors[i+1])<1.5: filter_colors[i+1] *= 1.5/np.sum(filter_colors[i+1])\n",
    "        filter_colors[i+1][filter_colors[i+1]>1.0] = 1.0\n",
    "\n",
    "##################################\n",
    "\n",
    "_, indexes = np.unique(loc_gids, return_index=True)\n",
    "translate_local2global = loc_gids[indexes]\n",
    "translate_global2local = -np.ones(np.max(translate_local2global)+1, np.int64)\n",
    "translate_global2local[translate_local2global] = range(len(translate_local2global))\n",
    "\n",
    "potentials2D = np.zeros((int(round((time_to-time_from)/dt))+1,len(translate_local2global)), np.float32)\n",
    "potentials2D[np.int64(np.round(id_times-time_from/dt)),translate_global2local[loc_gids]] = loc_potentials\n",
    "\n",
    "potentials2D_filter = potentials2D[:,np.argsort(loc_filters[indexes])]\n",
    "gid2color = filter_colors[convert[loc_filters[indexes]]+1][np.argsort(loc_filters[indexes])]\n",
    "\n",
    "nb_neurons = np.zeros(num_filter)\n",
    "ufilt = loc_filters[indexes]\n",
    "for i, uf in enumerate(uniq_filter):\n",
    "    nb_neurons[i] = len(np.where(ufilt==uf)[0])\n",
    "counts = np.zeros(num_filter+1)\n",
    "counts[1:] = np.cumsum(nb_neurons)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15, length_fr)) \n",
    "length_fr = int(math.ceil(num_filter/2.0))*2\n",
    "# Fig 3: Membrane heat plot\n",
    "time_interval = np.arange(time_from, time_to+dt/10., dt)\n",
    "for i in range(num_filter):\n",
    "    ax = plt.subplot2grid((length_fr,2), (i//2*2,i%2), rowspan=2)\n",
    "    mean = np.mean(potentials2D_filter[:, int(counts[i]):int(counts[i+1])], axis=1)\n",
    "    std = np.std(potentials2D_filter[:, int(counts[i]):int(counts[i+1])], axis=1)\n",
    "    ax.fill_between(time_interval, mean-std, mean+std, alpha=0.5, color=filter_colors[i+1])\n",
    "    ax.plot(time_interval, mean, c=filter_colors[i+1])\n",
    "    ax.set_xlabel('Time in ms')\n",
    "    ax.set_ylabel('Membrane voltage in mV')\n",
    "    ax.set_title('Mean membrane voltage other time for '+ names[inv_convert[i]])\n",
    "plt.tight_layout()\n",
    "plt.savefig(join(SIM_FOLDER, sim_name, splitter,sim_name+\"_\"+roi_name+\"_\"+splitter+\"_mean_membrane_potentials.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure(figsize=(15, 6))\n",
    "imshow(potentials2D_filter.T, interpolation=\"nearest\", cmap='hot', aspect=0.4, extent=[time_from,time_to, counts[-1], 0])\n",
    "cbar = colorbar()\n",
    "cbar.set_label('Membrane potential in mV', rotation=270)\n",
    "for il in range(1, num_filter):\n",
    "    plt.axhline(y=[counts[il]], color='b', linewidth=1)\n",
    "plt.xlabel('Time in ms')\n",
    "plt.ylabel('Neuron id')\n",
    "plt.tight_layout()\n",
    "plt.savefig(join(SIM_FOLDER, sim_name, splitter,sim_name+\"_\"+roi_name+\"_\"+splitter+\"_membrane_potentials.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1, figsize=(15,6))\n",
    "x = np.linspace(0, 10, 50)\n",
    "sp = np.abs(np.fft.fft(np.sin(x)))/float(len(x))\n",
    "fr = np.fft.fftfreq(len(x), 10.0/50.0)\n",
    "idx = np.argsort(fr)\n",
    "\n",
    "ax[0].plot(x,np.sin(x))\n",
    "# ax[1].plot(fr[idx][len(x)//2:], sp[idx][len(x)//2:]*2)\n",
    "ax[1].plot(fr[idx], sp[idx])\n",
    "ax[1].axvline(x=1/(2*np.pi))\n",
    "# ax[1].set_xlim([0,5])\n",
    "print(fr[np.argmax(sp)], 1/(2*np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(15, 6))\n",
    "ax = plt.subplot2grid((2,1), (0,0))\n",
    "i = 1\n",
    "firing = np.mean(potentials2D_filter[:,int(counts[i]):int(counts[i+1])], axis=1)\n",
    "ax.plot(firing)\n",
    "t = np.abs(np.fft.fft(firing))/float(R.shape[0])\n",
    "x = np.fft.fftfreq(t.shape[0], time_resolution)\n",
    "idx = np.argsort(x)\n",
    "ax = plt.subplot2grid((2,1), (1,0))\n",
    "ax.plot(x[idx][t.shape[0]//2:], t[idx][t.shape[0]//2:]*2)\n",
    "ax.set_xlim([0,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import elephant\n",
    "elephant.spectral.welch_psd(\n",
    "# delta = np.where(f<=4)\n",
    "# theta = np.where((f>4) & (f<=8))\n",
    "# alpha = np.where((f>8) & (f<=12))\n",
    "# beta  = np.where((f>12) & (f<=30))\n",
    "# gamma = np.where((f>30) & (f<=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# FFT\n",
    "fig = plt.figure(figsize=(15, length_fr))\n",
    "for i in range(num_filter):\n",
    "    ax = plt.subplot2grid((length_fr,2), (i//2*2,i%2), rowspan=2)\n",
    "    t = np.abs(np.fft.fft(np.mean(potentials2D_filter[:, int(counts[i]):int(counts[i+1])], axis=1)))/float(potentials2D_filter.shape[0])\n",
    "    x = np.fft.fftfreq(t.shape[0], time_resolution)\n",
    "    idx = np.argsort(x)\n",
    "    t = t[idx][t.shape[0]//2:] * 2\n",
    "    x = x[idx][x.shape[0]//2:]\n",
    "    ax.plot(x, t, color=filter_colors[i+1])\n",
    "    ax.set_xlabel('Frequency in Hz')\n",
    "    ax.set_title('Frequency spectrum for '+str(names[inv_convert[i]]))\n",
    "#     ax.set_xscale('log')\n",
    "    ax.set_xlim([0,1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(counts[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "#correlations matrices\n",
    "length_corr = int(math.ceil(num_filter/2.0))*5\n",
    "fig = plt.figure(figsize=(10, 10+length_corr))\n",
    "firing_rates =[]\n",
    "for i in range(num_filter):\n",
    "    spikes_pop = R[:, int(counts[i]):int(counts[i+1])]\n",
    "    firing_rates.append(np.mean(spikes_pop, axis=1))\n",
    "    ax = plt.subplot2grid((10+length_corr,2), (10+i//2*5,i%2), rowspan=5)\n",
    "    corr = np.corrcoef(spikes_pop.T, spikes_pop.T)\n",
    "    im = ax.imshow(corr[:len(corr)/2,:len(corr)/2])\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    fig.colorbar(im, cax=cax)\n",
    "    ax.set_title('Cross-correlation for '+str(names[inv_convert[i]]))\n",
    "corr = np.corrcoef(np.array(firing_rates), np.array(firing_rates))\n",
    "ax = plt.subplot2grid((10+length_corr,1), (0,0), rowspan=10)\n",
    "im = ax.imshow(corr[:len(corr)/2,:len(corr)/2])\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "fig.colorbar(im, cax=cax)\n",
    "ax.set_title('Activity correlation between populations')\n",
    "ax.set_xticks(np.arange(len(inv_convert)))\n",
    "ax.set_xticklabels(np.array(names)[inv_convert])\n",
    "ax.set_yticks(np.arange(len(inv_convert)))\n",
    "ax.set_yticklabels(np.array(names)[inv_convert])\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
